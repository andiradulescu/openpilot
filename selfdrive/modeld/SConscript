import os
import glob

Import('env', 'envCython', 'arch', 'cereal', 'messaging', 'common', 'gpucommon', 'visionipc', 'transformations')
lenv = env.Clone()
lenvCython = envCython.Clone()

libs = [cereal, messaging, visionipc, gpucommon, common, 'capnp', 'kj', 'pthread']
frameworks = []

common_src = [
  "models/commonmodel.cc",
  "transforms/loadyuv.cc",
  "transforms/transform.cc",
]

if arch == "Darwin":
  # OpenCL is a framework on Mac
  frameworks += ['OpenCL']
  # Fix for METAL Error: $HOME must be set to run brew
  lenv['ENV']['HOME'] = os.environ['HOME']
else:
  libs += ['OpenCL']

# Set path definitions
for pathdef, fn in {'TRANSFORM': 'transforms/transform.cl', 'LOADYUV': 'transforms/loadyuv.cl'}.items():
  for xenv in (lenv, lenvCython):
    xenv['CXXFLAGS'].append(f'-D{pathdef}_PATH=\\"{File(fn).abspath}\\"')

# Compile cython
cython_libs = envCython["LIBS"] + libs
commonmodel_lib = lenv.Library('commonmodel', common_src)
lenvCython.Program('models/commonmodel_pyx.so', 'models/commonmodel_pyx.pyx', LIBS=[commonmodel_lib, *cython_libs], FRAMEWORKS=frameworks)
tinygrad_files = ["#"+x for x in glob.glob(env.Dir("#tinygrad_repo").relpath + "/**", recursive=True, root_dir=env.Dir("#").abspath) if 'pycache' not in x]

# Get model metadata
for model_name in ['driving_vision', 'driving_policy']:
  fn = File(f"models/{model_name}").abspath
  script_files = [File(Dir("#selfdrive/modeld").File("get_model_metadata.py").abspath)]
  cmd = f'python3 {Dir("#selfdrive/modeld").abspath}/get_model_metadata.py {fn}.onnx'
  lenv.Command(fn + "_metadata.pkl", [fn + ".onnx"] + tinygrad_files + script_files, cmd)

def tg_compile(flags, model_name):
  pythonpath_string = 'PYTHONPATH="${PYTHONPATH}:' + env.Dir("#tinygrad_repo").abspath + '"'
  fn = File(f"models/{model_name}").abspath
  return lenv.Command(
    fn + "_tinygrad.pkl",
    [fn + ".onnx"] + tinygrad_files,
    f'{pythonpath_string} {flags} python3 {Dir("#tinygrad_repo").abspath}/examples/openpilot/compile3.py {fn}.onnx {fn}_tinygrad.pkl'
  )

# because tg doesn't support multi-process
import subprocess

def get_backend_flags():
  try:
    devs = subprocess.check_output('python3 -c "from tinygrad import Device; print(list(Device.get_available_devices()))"', shell=True, cwd=env.Dir('#').abspath)
    print("Available tinygrad devices:", devs)
    
    # Try to detect and test backend capabilities
    if b"QCOM" in devs:
      try:
        # Test QCOM backend compilation
        test_cmd = 'python3 -c "import os; os.environ[\'QCOM\']=\'1\'; from tinygrad import Tensor; Tensor.zeros(1).realize()"'
        subprocess.check_output(test_cmd, shell=True, cwd=env.Dir('#').abspath, stderr=subprocess.STDOUT)
        return 'QCOM=1'
      except subprocess.CalledProcessError as e:
        print(f"QCOM backend test failed: {e}, falling back to CPU")
        
    elif b"METAL" in devs:
      try:
        # Test METAL backend compilation  
        test_cmd = 'python3 -c "import os; os.environ[\'METAL\']=\'1\'; os.environ[\'IMAGE\']=\'0\'; os.environ[\'NOLOCALS\']=\'0\'; from tinygrad import Tensor; Tensor.zeros(1).realize()"'
        subprocess.check_output(test_cmd, shell=True, cwd=env.Dir('#').abspath, stderr=subprocess.STDOUT)
        return 'METAL=1 IMAGE=0 NOLOCALS=0'
      except subprocess.CalledProcessError as e:
        print(f"METAL backend test failed: {e}, falling back to CPU")
        
    elif b"GPU" in devs:
      try:
        # Test GPU backend compilation
        test_cmd = 'python3 -c "import os; os.environ[\'GPU\']=\'1\'; from tinygrad import Tensor; Tensor.zeros(1).realize()"'
        subprocess.check_output(test_cmd, shell=True, cwd=env.Dir('#').abspath, stderr=subprocess.STDOUT)
        return 'GPU=1'
      except subprocess.CalledProcessError as e:
        print(f"GPU backend test failed: {e}, falling back to CPU")
        
    elif b"LLVM" in devs:
      try:
        # Test LLVM backend compilation
        test_cmd = 'python3 -c "import os; os.environ[\'LLVM\']=\'1\'; os.environ[\'LLVMOPT\']=\'1\'; os.environ[\'BEAM\']=\'0\'; os.environ[\'IMAGE\']=\'0\'; os.environ[\'JIT\']=\'2\'; from tinygrad import Tensor; Tensor.zeros(1).realize()"'
        subprocess.check_output(test_cmd, shell=True, cwd=env.Dir('#').abspath, stderr=subprocess.STDOUT)
        return 'LLVM=1 LLVMOPT=1 BEAM=0 IMAGE=0 JIT=2'
      except subprocess.CalledProcessError as e:
        print(f"LLVM backend test failed: {e}, falling back to CPU")
        
  except Exception as e:
    print(f"Backend detection failed: {e}, falling back to CPU")
  
  # Always fallback to CPU if any detection or testing fails
  print("Using CPU backend as fallback")
  return 'CPU=1 IMAGE=0 JIT=2'

flags = get_backend_flags()

print(f"Compiling models with flags: '{flags}'")

# Compile small models
for model_name in ['driving_vision', 'driving_policy', 'dmonitoring_model']:
  tg_compile(flags, model_name)

# Compile BIG model if USB GPU is available
if "USBGPU" in os.environ:
  if b"AMD" in devs:
    print("USB GPU detected... building")
    flags = "AMD=1 AMD_IFACE=USB AMD_LLVM=1 NOLOCALS=0 IMAGE=0"
    bp = tg_compile(flags, "big_driving_policy")
    bv = tg_compile(flags, "big_driving_vision")
    lenv.SideEffect('lock', [bp, bv])  # tg doesn't support multi-process so build serially
  else:
    print("USB GPU not detected... skipping")
